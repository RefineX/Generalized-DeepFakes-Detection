{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt0a5k8RUA/US8mdkFbD+p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RefineX/Generalized-DeepFakes-Detection/blob/master/AML_Initial_Model_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install image-classifiers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gRRiXuberuln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8274b6b1-6bd7-4cfd-ed9b-ec450c83ed07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting image-classifiers\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->image-classifiers) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->image-classifiers) (1.21.6)\n",
            "Installing collected packages: keras-applications, image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Downloader\n",
        "dataset = \"LEVIRCD_Plus\" #@param [\"S2Looking\", \"LEVIRCD_Plus\"]\n",
        "resize = \"512\" #@param [\"1024\", \"512\", \"256\"]\n",
        "crop = \"256\" #@param [\"1024\", \"512\", \"256\"]\n",
        "\n",
        "data_link_dict = {\n",
        "    'S2Looking': {\n",
        "      '1024_512': \"1-0_vcODMYmyYIY_uhMcs97aAk2OJVduq&confirm=t\",\n",
        "      '1024_256': \"1-0mVd6BjKnG3LXhYkbyxdx0-dtRKY6KO&confirm=t\",\n",
        "      '512_512': \"1-6WOmE0LTJ4Z31EphmA0L8QY5NMMllsT&confirm=t\",\n",
        "      '512_256': \"1-7NSOmHTsDpkEtbgt_N4VSgipCo5kr3a&confirm=t\",\n",
        "      '256_256': \"1-8x5d5DrNsgJ5eAOYyKwi91g8knGeRjQ&confirm=t\",\n",
        "      '1024_1024': \"1GzrgMwJKguXSWSfFsBSC2qSr52fVEc7W&confirm=t\"\n",
        "    },\n",
        "    'LEVIRCD_Plus': {\n",
        "      '1024_512': \"1-22GjfF8mlLFNyoJaa6_GMJRfTCoGZyc&confirm=t\",\n",
        "      '1024_256': \"1-2r-zCCfQjLRtwwXMGPYAxEJcTS8Hp80&confirm=t\",\n",
        "      '512_512': \"1-43scZrxe3Q_PH2EnBRuc_6l9O9WjPs2&confirm=t\",\n",
        "      '512_256': \"1-5oC0xV36S4K5VMiQuwheWoyMt1ymYb9&confirm=t\",\n",
        "      '256_256': \"1-69cdgqlcXunt5vrCR9jRvcMkpPNzYWr&confirm=t\",\n",
        "      '1024_1024': \"1nyPJZGGOL7o8A0m0rGw7wyu2BFIxC4SD&confirm=t\"\n",
        "    }\n",
        "}\n",
        "\n",
        "import os\n",
        "if os.path.exists(f'Data/{dataset}/{resize}_{crop}'):\n",
        "  print('This dataset already exists.')\n",
        "else:\n",
        "  gdown_link = data_link_dict[dataset][f'{resize}_{crop}']\n",
        "  !gdown \"{gdown_link}\"\n",
        "  print('Unzipping...',end='')\n",
        "  !unzip -q \"{resize}_{crop}.zip\"\n",
        "  print('Done.\\nDeleting zip...',end='')\n",
        "  !rm \"{resize}_{crop}.zip\"\n",
        "  print('Done.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "jdXkHvK6gGr7",
        "outputId": "6fea3c60-423b-4396-a6af-69dec2d80714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-5oC0xV36S4K5VMiQuwheWoyMt1ymYb9&confirm=t\n",
            "To: /content/512_256.zip\n",
            "100% 317M/317M [00:04<00:00, 63.5MB/s]\n",
            "Unzipping...Done.\n",
            "Deleting zip...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "import cv2"
      ],
      "metadata": {
        "id": "B9GQ_AA1i5Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Characteristics\n",
        "dataset = \"LEVIRCD_Plus\" #@param [\"S2Looking\", \"LEVIRCD_Plus\"]\n",
        "resized_size = \"512\" #@param [1024, 512, 256]\n",
        "crop_size = \"256\" #@param [1024, 512, 256]\n",
        "resized_size = int(resized_size)\n",
        "crop_size = int(crop_size)\n",
        "if dataset == 'S2Looking':\n",
        "  pre_image = 'Image1'\n",
        "  post_image = 'Image2'\n",
        "elif dataset == 'LEVIRCD_Plus':\n",
        "  pre_image = 'A'\n",
        "  post_image = 'B'\n",
        "label_image = 'label'\n",
        "PATH = f\"/content/Data/{dataset}/{resized_size}_{crop_size}\"\n",
        "Path('saved/models/').mkdir(parents=True, exist_ok=True)\n",
        "Path('saved/histories/').mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AFi5x75Ek8IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "\n",
        "def iou(y_true,y_pred):\n",
        "  y_pred = tf.argmax(y_pred,-1)\n",
        "  y_true = tf.argmax(y_true,-1)\n",
        "  tp = tf.cast(tf.reduce_sum(y_pred*y_true,axis=[1,2]), 'float32')\n",
        "  fp = tf.cast(tf.reduce_sum(y_pred*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fn = tf.cast(tf.reduce_sum((1-y_pred)*y_true,axis=[1,2]), 'float32')\n",
        "  iou_value = (tp + 1e-14) / (tp + fp + fn + 1e-14)\n",
        "  return tf.reduce_mean(iou_value)\n",
        "\n",
        "def miou(y_true,y_pred):\n",
        "  y_pred = tf.argmax(y_pred,-1)\n",
        "  y_true = tf.argmax(y_true,-1)\n",
        "  tp = tf.cast(tf.reduce_sum(y_pred*y_true,axis=[1,2]), 'float32')\n",
        "  tn = tf.cast(tf.reduce_sum((1-y_pred)*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fp = tf.cast(tf.reduce_sum(y_pred*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fn = tf.cast(tf.reduce_sum((1-y_pred)*y_true,axis=[1,2]), 'float32')\n",
        "  iou1 = (tp + 1e-14) / (tp + fp + fn + 1e-14)\n",
        "  iou2 = (tn + 1e-14) / (tn + fp + fn + 1e-14)\n",
        "  iou_value = (iou1 + iou2) / 2\n",
        "  return tf.reduce_mean(iou_value)\n",
        "\n",
        "# Losses"
      ],
      "metadata": {
        "id": "JGxDUbzFp6IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from classification_models.tfkeras import Classifiers\n",
        "import pickle\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "O3mqAH-HyxjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "es_patience = 15\n",
        "rLR_patience = 5\n",
        "lr = 1e-2\n",
        "optimizer = Adam(learning_rate = lr)\n",
        "loss = 'categorical_crossentropy'\n",
        "BATCH_SIZE = 16\n",
        "metrics = [iou, 'accuracy']"
      ],
      "metadata": {
        "id": "3UI_uqydsmA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 Data"
      ],
      "metadata": {
        "id": "q3wjGHs6hrsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions for Model #1\n",
        "def load(imageA_file):\n",
        "  imageA = tf.io.read_file(imageA_file)\n",
        "  imageA = tf.image.decode_png(imageA)[:,:,:3]\n",
        "\n",
        "  imageB_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{post_image}/')\n",
        "  imageB = tf.io.read_file(imageB_file)\n",
        "  imageB = tf.image.decode_jpeg(imageB)[:,:,:3]\n",
        "\n",
        "  label_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{label_image}/')\n",
        "  label_file = tf.strings.regex_replace(label_file, '.jpg', '.png')\n",
        "  label = tf.io.read_file(label_file)\n",
        "  label = tf.image.decode_png(label)[:,:,0]\n",
        "\n",
        "  imageA = tf.cast(imageA,tf.float32)\n",
        "  imageB = tf.cast(imageB,tf.float32)\n",
        "  image = tf.concat([imageA,imageB],axis=-1)\n",
        "  label = tf.cast(label,tf.float32)\n",
        "  label = tf.stack([255-label,label],axis=-1)\n",
        "\n",
        "  return image, label\n",
        "\n",
        "def normalize(image, label):\n",
        "  image = image / 255\n",
        "  label = label / 255\n",
        "  return image, label\n",
        "\n",
        "def load_image(image_file):\n",
        "  image, label = load(image_file)\n",
        "  image, label = normalize(image, label)\n",
        "  return image, label\n",
        "\n",
        "train_dataset = tf.data.Dataset.list_files(f'{PATH}/train/{pre_image}/*.jpg')\n",
        "train_dataset = train_dataset.shuffle(1000)\n",
        "train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "train_dataset_length = len(train_dataset)\n",
        "# train_dataset_length = int(np.ceil(len(os.listdir(f'{PATH}/train/{pre_image}/'))/BATCH_SIZE))\n",
        "\n",
        "val_dataset = tf.data.Dataset.list_files(f'{PATH}/val/{pre_image}/*.jpg')\n",
        "val_dataset = val_dataset.map(load_image)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "val_dataset_length = len(val_dataset)\n",
        "# val_dataset_length = int(np.ceil(len(os.listdir(f'{PATH}/train/{pre_image}/'))/BATCH_SIZE))\n",
        "\n",
        "test_dataset = tf.data.Dataset.list_files(f'{PATH}/test/{pre_image}/*.jpg')\n",
        "test_dataset = test_dataset.map(load_image)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset_length = len(test_dataset)\n",
        "# test_dataset_length = len(os.listdir(f'{PATH}/train/{pre_image}/'))\n",
        "\n",
        "print(f'train_dataset_length: {train_dataset_length}, val_dataset_length: {val_dataset_length}, test_dataset_length: {test_dataset_length}')"
      ],
      "metadata": {
        "id": "7uCJTn1Ot3pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abeeca38-4ab2-4c96-979e-f54959a98576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_length: 128, val_dataset_length: 32, test_dataset_length: 87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "UDElGWyhhuYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model #1\n",
        "def ef_model(input_shape = (256, 256, 6), backbone = 'resnet18'):\n",
        "\n",
        "  ResNet18, preprocess_input = Classifiers.get(backbone)\n",
        "  encoder = ResNet18(input_shape, weights=None,include_top=False)\n",
        "  encoder_output = encoder.output\n",
        "  skip_outputs = [encoder.get_layer(f).output for f in ['stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0']]\n",
        "\n",
        "  def conv_bn_relu(filters,x):\n",
        "    x = Conv2D(filters, 3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "  x = encoder_output\n",
        "  for i,skip_output in enumerate(skip_outputs):\n",
        "    x = UpSampling2D(name=f'up{i+1}')(x)\n",
        "    filters = skip_output.shape[-1]\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = concatenate([x, skip_output])\n",
        "  x = UpSampling2D(name='up5')(x)\n",
        "  for filters in [32,32,16,16]:\n",
        "    x = conv_bn_relu(filters,x)\n",
        "  x = Conv2D(2, 1, activation = 'softmax', padding='same', kernel_initializer='he_uniform', dtype = 'float32')(x)\n",
        "  model = Model(inputs = encoder.inputs, outputs = x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "5AN_EYMubtCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model #1\n",
        "input_shape = (crop_size, crop_size, 6)\n",
        "backbone = 'resnet18'\n",
        "model = ef_model(input_shape, backbone)\n",
        "model_name = 'model_ef'\n",
        "model_path = f'saved/models/{dataset}_{backbone}_{model_name}.h5'\n",
        "history_path = f'saved/histories/{dataset}_{backbone}_{model_name}.pkl'\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_iou', mode='max', save_best_only=True, verbose = 1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_iou', mode = 'max', factor=1/np.sqrt(10), patience = rLR_patience, min_lr=1e-6, verbose = 1)\n",
        "earlystopper = EarlyStopping(monitor='val_iou', mode = 'max', patience = es_patience, verbose=1)\n",
        "callbacks = [checkpoint, reduce_lr, earlystopper]\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
        "hist = model.fit(train_dataset, epochs = epochs, validation_data = val_dataset, callbacks = callbacks)\n",
        "with open(history_path, 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "model.load_weights(model_path)\n",
        "_, test_iou, _ = model.evaluate(test_dataset)\n",
        "os.rename(model_path, model_path.replace('.h5',f'_{test_iou:.4f}.h5'))\n",
        "os.rename(history_path, history_path.replace('.pkl',f'_{test_iou:.4f}.pkl'))\n",
        "plt.plot(hist.history['iou'])\n",
        "plt.plot(hist.history['val_iou'])\n",
        "plt.title('model iou')\n",
        "plt.ylabel('iou')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n27RJ_hKb0Hy",
        "outputId": "bf006785-49b2-4671-abc1-ddf78f42d95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128/128 [==============================] - ETA: 0s - loss: 0.1218 - iou: 0.3448 - accuracy: 0.9579\n",
            "Epoch 1: val_iou improved from -inf to 0.33344, saving model to saved/models/LEVIRCD_Plus_resnet18_model_ef.h5\n",
            "128/128 [==============================] - 56s 237ms/step - loss: 0.1218 - iou: 0.3448 - accuracy: 0.9579 - val_loss: 0.3209 - val_iou: 0.3334 - val_accuracy: 0.9511 - lr: 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 34). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87/87 [==============================] - 16s 188ms/step - loss: 0.2652 - iou: 0.3662 - accuracy: 0.9594\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2/3 Data"
      ],
      "metadata": {
        "id": "meOvZpk-hogb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions for Model #2 and #3\n",
        "def load(imageA_file):\n",
        "  imageA = tf.io.read_file(imageA_file)\n",
        "  imageA = tf.image.decode_png(imageA)[:,:,:3]\n",
        "\n",
        "  imageB_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{post_image}/')\n",
        "  imageB = tf.io.read_file(imageB_file)\n",
        "  imageB = tf.image.decode_jpeg(imageB)[:,:,:3]\n",
        "\n",
        "  label_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{label_image}/')\n",
        "  label_file = tf.strings.regex_replace(label_file, '.jpg', '.png')\n",
        "  label = tf.io.read_file(label_file)\n",
        "  label = tf.image.decode_png(label)[:,:,0]\n",
        "\n",
        "  imageA = tf.cast(imageA,tf.float32)\n",
        "  imageB = tf.cast(imageB,tf.float32)\n",
        "  # image = tf.concat([imageA,imageB],axis=-1)\n",
        "  label = tf.cast(label,tf.float32)\n",
        "  label = tf.stack([255-label,label],axis=-1)\n",
        "\n",
        "  return imageA, imageB, label\n",
        "\n",
        "def normalize(imageA, imageB, label):\n",
        "  imageA = imageA / 255\n",
        "  imageB = imageB / 255\n",
        "  label = label / 255\n",
        "  return imageA, imageB, label\n",
        "\n",
        "def load_image(image_file):\n",
        "  imageA, imageB, label = load(image_file)\n",
        "  imageA, imageB, label = normalize(imageA, imageB, label)\n",
        "  return (imageA, imageB), label\n",
        "\n",
        "train_dataset = tf.data.Dataset.list_files(f'{PATH}/train/{pre_image}/*.jpg')\n",
        "train_dataset = train_dataset.shuffle(1000)\n",
        "train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "train_dataset_length = len(train_dataset)\n",
        "# train_dataset_length = int(np.ceil(len(os.listdir(f'{PATH}/train/{pre_image}/'))/BATCH_SIZE))\n",
        "\n",
        "val_dataset = tf.data.Dataset.list_files(f'{PATH}/val/{pre_image}/*.jpg')\n",
        "val_dataset = val_dataset.map(load_image)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "val_dataset_length = len(val_dataset)\n",
        "# val_dataset_length = int(np.ceil(len(os.listdir(f'{PATH}/train/{pre_image}/'))/BATCH_SIZE))\n",
        "\n",
        "test_dataset = tf.data.Dataset.list_files(f'{PATH}/test/{pre_image}/*.jpg')\n",
        "test_dataset = test_dataset.map(load_image)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset_length = len(test_dataset)\n",
        "# test_dataset_length = len(os.listdir(f'{PATH}/train/{pre_image}/'))\n",
        "\n",
        "print(f'train_dataset_length: {train_dataset_length}, val_dataset_length: {val_dataset_length}, test_dataset_length: {test_dataset_length}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qilX5p3ckcON",
        "outputId": "b6c94fe1-3600-4d99-ab95-03a5895dd374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_length: 64, val_dataset_length: 64, test_dataset_length: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "vQmQV19NhhJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2\n",
        "def siamconc_model(input_shape = (256, 256, 3), backbone = 'resnet18'):\n",
        "\n",
        "  ResNet18, preprocess_input = Classifiers.get(backbone)\n",
        "  encoder = ResNet18(input_shape, weights=None,include_top=False)\n",
        "  encoder_output = [encoder.output]\n",
        "  skip_outputs = [encoder.get_layer(f).output for f in ['stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0']]\n",
        "  skips_model = Model(inputs = encoder.inputs, outputs = encoder_output + skip_outputs)\n",
        "  inputA = Input((crop_size, crop_size, 3))\n",
        "  inputB = Input((crop_size, crop_size, 3))\n",
        "  skipsA = skips_model(inputA)\n",
        "  skipsB = skips_model(inputB)\n",
        "\n",
        "  def conv_bn_relu(filters,x):\n",
        "    x = Conv2D(filters, 3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "  x = concatenate([skipsA[0], skipsB[0]])\n",
        "  for i,(skipA, skipB) in enumerate(zip(skipsA[1:], skipsB[1:])):\n",
        "    x = UpSampling2D(name=f'up{i+1}')(x)\n",
        "    filters = skipA.shape[-1]\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = concatenate([x, skipA, skipB])\n",
        "  x = UpSampling2D(name='up5')(x)\n",
        "  for filters in [32,32,16,16]:\n",
        "    x = conv_bn_relu(filters,x)\n",
        "  x = Conv2D(2, 1, activation = 'softmax', padding='same', kernel_initializer='he_uniform', dtype = 'float32')(x)\n",
        "  model = Model(inputs = [inputA, inputB], outputs = x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "E8NuEsnstNYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model #2\n",
        "input_shape = (crop_size, crop_size, 3)\n",
        "backbone = 'resnet18'\n",
        "model = siamconc_model(input_shape, backbone)\n",
        "model_name = 'model_siamconc'\n",
        "model_path = f'saved/models/{dataset}_{backbone}_{model_name}.h5'\n",
        "history_path = f'saved/histories/{dataset}_{backbone}_{model_name}.pkl'\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_iou', mode='max', save_best_only=True, verbose = 1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_iou', mode = 'max', factor=1/np.sqrt(10), patience = rLR_patience, min_lr=1e-6, verbose = 1)\n",
        "earlystopper = EarlyStopping(monitor='val_iou', mode = 'max', patience = es_patience, verbose=1)\n",
        "callbacks = [checkpoint, reduce_lr, earlystopper]\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
        "hist = model.fit(train_dataset, epochs = epochs, validation_data = val_dataset, callbacks = callbacks)\n",
        "with open(history_path, 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "model.load_weights(model_path)\n",
        "_, test_iou, _ = model.evaluate(test_dataset)\n",
        "os.rename(model_path, model_path.replace('.h5',f'_{test_iou:.4f}.h5'))\n",
        "os.rename(history_path, history_path.replace('.pkl',f'_{test_iou:.4f}.pkl'))\n",
        "plt.plot(hist.history['iou'])\n",
        "plt.plot(hist.history['val_iou'])\n",
        "plt.title('model iou')\n",
        "plt.ylabel('iou')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sp1mlciDtKWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ],
      "metadata": {
        "id": "zJiGoBr0hmHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 3\n",
        "def siamdiff_model(input_shape = (256, 256, 3), backbone = 'resnet18'):\n",
        "\n",
        "  ResNet18, preprocess_input = Classifiers.get(backbone)\n",
        "  encoder = ResNet18(input_shape, weights=None,include_top=False)\n",
        "  encoder_output = [encoder.output]\n",
        "  skip_outputs = [encoder.get_layer(f).output for f in ['stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0']]\n",
        "  skips_model = Model(inputs = encoder.inputs, outputs = encoder_output + skip_outputs)\n",
        "  inputA = Input((crop_size, crop_size, 3))\n",
        "  inputB = Input((crop_size, crop_size, 3))\n",
        "  skipsA = skips_model(inputA)\n",
        "  skipsB = skips_model(inputB)\n",
        "\n",
        "  def conv_bn_relu(filters,x):\n",
        "    x = Conv2D(filters, 3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "  x = concatenate([skipsA[0], skipsB[0]])\n",
        "  for i,(skipA, skipB) in enumerate(zip(skipsA[1:], skipsB[1:])):\n",
        "    x = UpSampling2D(name=f'up{i+1}')(x)\n",
        "    filters = skipA.shape[-1]\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = concatenate([x, skipA - skipB])\n",
        "  x = UpSampling2D(name='up5')(x)\n",
        "  for filters in [32,32,16,16]:\n",
        "    x = conv_bn_relu(filters,x)\n",
        "  x = Conv2D(2, 1, activation = 'softmax', padding='same', kernel_initializer='he_uniform', dtype = 'float32')(x)\n",
        "  model = Model(inputs = [inputA, inputB], outputs = x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "N8fGCXH3tkKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model #3\n",
        "input_shape = (crop_size, crop_size, 3)\n",
        "backbone = 'resnet18'\n",
        "model = siamdiff_model(input_shape, backbone)\n",
        "model_name = 'model_siamdiff'\n",
        "model_path = f'saved/models/{dataset}_{backbone}_{model_name}.h5'\n",
        "history_path = f'saved/histories/{dataset}_{backbone}_{model_name}.pkl'\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_iou', mode='max', save_best_only=True, verbose = 1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_iou', mode = 'max', factor=1/np.sqrt(10), patience = rLR_patience, min_lr=1e-6, verbose = 1)\n",
        "earlystopper = EarlyStopping(monitor='val_iou', mode = 'max', patience = es_patience, verbose=1)\n",
        "callbacks = [checkpoint, reduce_lr, earlystopper]\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
        "hist = model.fit(train_dataset, epochs = epochs, validation_data = val_dataset, callbacks = callbacks)\n",
        "with open(history_path, 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "model.load_weights(model_path)\n",
        "_, test_iou, _ = model.evaluate(test_dataset)\n",
        "os.rename(model_path, model_path.replace('.h5',f'_{test_iou:.4f}.h5'))\n",
        "os.rename(history_path, history_path.replace('.pkl',f'_{test_iou:.4f}.pkl'))\n",
        "plt.plot(hist.history['iou'])\n",
        "plt.plot(hist.history['val_iou'])\n",
        "plt.title('model iou')\n",
        "plt.ylabel('iou')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yf_YGoszkQFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move savefile to drive"
      ],
      "metadata": {
        "id": "7uqiwkibhyo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r saved.zip saved/\n",
        "!cp saved.zip /content/drive/MyDrive/saved.zip"
      ],
      "metadata": {
        "id": "_maxz9GaWg2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}